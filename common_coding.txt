1. Common Practices
    - list related
        -- .item() - get a single number out of a list/tensor as a python regular int/float
        -- set(list) - create a set object that contains unique values in the list
        -- sorted(list) - create a list object that contains sorted values in the list
        -- itemgetter(*index_list)(list) - retrieve multiple items from a list with a list of index, operator module
        -- list(map(function, target)) - apply the function on elements of target
        -- list.index(element, start, end) - locate index of element from start to end positions
    
    - object: Random
        -- random.choice(list) - choose a random sample from the list
        -- random.sample(list,k=n) - choose n random samples from the list
    
    - object: Dictionary
        -- for key in dict: - retrieve the keys
        -- for item in dict.items(): - retrieve the items
        -- dict.get(key,alt_value) - retrieve value from key, if not found, return alt_value
        -- itemgetter(*keys)(dict) - retrieve items corresponding to the keys
        -- with open(path, "wb") as f: pickle.dump(dict,f) - save Dictionary
        -- with open(path, "rb") as f: dict=pickle.load(f) - load Dictionary
        -- max(stats, key=dict.get) - retrieve the value where the key is the largest
        -- sorted(dict.items(),key=lambda x: x[1], reverse=True) - sort dictionary based on value
    
    - copy files with shutil
        -- shutil.copyfile(path_from,path_to)
    
    - Try and Assert
        -- assert condition, "message"
        -- try, except
            try:
                condition
            except:
                action if condition fail
            else:
                action if condition didn't fail
            finally:
                action regardless of condition
    
    - object: tqdm
        from tqdm.auto import tqdm
        -- progress_bar = tqdm(range(num_steps))
        -- progress_bar.update(step)
    
    - object: string
        -- string.find(pattern,start,end) - find the index where the pattern occurred
        -- "a d c b".split(" ") ---> ["a", "d", "c", "b"]
        -- "|".join(["a", "b", "c"]) ---> "a|b|c"
        -- string.strip() - removing leading and trailing white spaces

    - Zip
        -- list(zip([1,2], [11,22])) --> [(1,11),(2,22)]
    
    - pip install to a different location
        -- pip install --target=path library_to_be_installed
    
    - enforcing argument data type
        from typing import Optional
        -- def fn(text:Optional[str]) - forcing it to be string or None type
        from typing import Union
        -- def fn(value:Union[str, int]) - forcing it to be string or integer
    
    - object: Numpy
        -- saving and loading
            with open("test.npy", "wb") as f:
                np.save(f,np.array([1,2]))
                np.save(f,np.array([3,4]))
            with open("test.npy","rb") as f:
                a = np.load(f)
                b = np.load(f)
            print(a, b) --> [1,2] [3,4]
    
    - object: Path from pathlib
        -- p = Path("C:\\A\\B\\c.exe")
        -- str(p.parent) --> "C:\\A\\B"
        -- p.name --> "c.exe"
        -- p.suffix --> ".exe"
        -- p.parts --> ("C:\\", "A", "B", "c.exe")
        -- p.relative_to("C:\\A") --> WindowsPath("B/c.exe")
        -- p.exists() --> True

    - write out as txt files
        -- if os.path.exists(path): os.makedirs(path)
        -- f = open(path,"w"/"a") - overwrite everything and create new file/append or create new file
        -- f.write(message)
        -- f.close()


2. PyTorch
    - common functions
        -- torch.cat((a,b), dim=0) - concatenate two tensors along the 0th dimension
        -- 

    - device
        -- device = "cuda" if torch.cuda.is_available() else "cpu"
        -- next(model.parameters()).device
    
    - common practice for train and test loop
        -- with torh.inference_mode() - set up inference mode for testing/validating
        -- pred_labels = torch.round(model_output) - get predicted labels for binary classification
        -- pred_labels = model_output.argmax(dim=1) - ....................... multiclass classification
        -- opotimizer.zero_grad() - clear cache of optimizer (previous gradients)
        -- loss.backward() - backpropagation
        -- optimizer.step() - parameter updates
        -- torch.eq(tensor1, tensor2).sum().item() - calculating correct predictions
    
    - data types
        -- a.long() - convert torch tensor a from float(usually) to int64
        -- a.float() - convert torch tensor a from int(usually) to float32
    
    - save & load models
        -- torch.save(model.state_dict(), PATH)
        -- model.load_state_dict(torch.load(PATH))
    
    - extract tensor element
        -- a[0].detach().cpu().numpy().item()






Saving array as text, load with np
    - flat array
        -- sample_array = [32, 1446, 101, 1280]
        -- a = list(map(str,sample_array)) --> ["32", "1446", "101", "1280"]
        -- b = " ".join(a) --> "32 1446 101 1280"
        -- with open("test.txt","w") as f: f.write(b)
        -- c = np.loadtxt("test.txt",dtype=int)
    - nested array - process
        -- sample_array = [[1, 2], [3, 4]]
        -- a = str(sample_array)
        -- a = a[1:-2] --> "[1, 2], [3, 4"
        -- a = a.replace("[","") --> "1, 2], [3, 4"
        -- a = a.replace("]","\n") --> "1, 2\n, 3, 4"
        -- a = a.replace(",", "") --> "1 2\n 3 4"
        -- with open("test.txt","w") as f: f.write(a)
    - nested array - decode
        -- txt_array = "1 2\n 3 4"
        -- a = text_array.split("\n") --> ["1 2", " 3 4"]
        -- a = [[int(num) for num in block.strip().split(" ")] for block in a]
        --> [[1, 2], [3, 4]]

Image dataset
    - __init__ --> store image folder path, transform, and list of all file names in folder
    - __len__ --> return number of files in the folder
    - __getitem__ (idx)
        1. construct complete path of a image (corresponding to idx)
        2. read image data
        3. apply transformation
        4. return image


Convolutional dimensions calculation
    - define
        -- input dimension = i
        -- kernel size = k
        -- stride size = s 
        -- padding size = p 
        -- output dimension = o 

    - convolutional layer calculation
        -- o = (i + 2p - k) / s + 1

    - transposed covolutional layer calculation
        -- o = (i - 1) * s + k - 2p


Pycocotools
    from pycocotools.coco import coco

    define
        - annotation_path = "........../captions_train2017.json"
        - image_directory = "........../images/train2017"
        - coco = COCO(annotation_path)

    coco keys
        - anns
        - dataset, cats, imgs, imgToAnns, cattoImgs

    anns
        - anns.keys ---> indicies, or id (for dataset and dataloader) --> e.g., [37, 49, 89, 98, 101]
        - coco.anns[id] ---> {'image_id': 2222, 'id': 2, 'caption': "abcdefg"}
        - coco.loadImgs(image_id)[0] ----> {'license':x, 'file_name': '000002155.jpg',
                                            'height':480, 'width':460, 'date_captured',
                                            'coco_url','flickr_url','id'}

    access image through file_name and image_directory
        - Image.open(path.join(dir,file_name)).convert("RGB")



